{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"clothing_shoes_jewelry.txt\")\n",
    "new_file=open(\"new_file.txt\",\"w\")\n",
    "for line in file:\n",
    "    if 'reviewText' in line:\n",
    "        new_file.write(line)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')\n",
    "Text = mycorpus.raw(\"new_file.txt\")\n",
    "Text = Text.replace(\"reviewText:\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokens = nltk.word_tokenize(Text) #Converts the text into tokens\n",
    "Words = [w.lower() for w in Tokens] #Converts all the token into lower case words\n",
    "RevisedWords = [w for w in Words if w.isalpha()] #Only words consisting of alphabets are stored in RevisedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = nltk.corpus.stopwords.words('english')\n",
    "StoppedRevisedWords = [w for w in RevisedWords if w not in Stopwords] #Removed stop words to get a clearer picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('like', 90212)\n",
      "('size', 85325)\n",
      "('fit', 80248)\n",
      "('wear', 79775)\n",
      "('great', 78392)\n",
      "('would', 67419)\n",
      "('good', 60382)\n",
      "('love', 60148)\n",
      "('well', 58211)\n",
      "('comfortable', 57492)\n",
      "('one', 56475)\n",
      "('shoes', 50444)\n",
      "('really', 46108)\n",
      "('nice', 46101)\n",
      "('little', 42750)\n",
      "('look', 42677)\n",
      "('bought', 42611)\n",
      "('get', 38875)\n",
      "('price', 34828)\n",
      "('color', 33823)\n",
      "('pair', 33641)\n",
      "('quality', 33293)\n",
      "('small', 32928)\n",
      "('time', 32872)\n",
      "('ordered', 32734)\n",
      "('perfect', 31904)\n",
      "('shoe', 31523)\n",
      "('also', 30148)\n",
      "('much', 29976)\n",
      "('buy', 29284)\n",
      "('got', 29009)\n",
      "('made', 28195)\n",
      "('looks', 27625)\n",
      "('watch', 26975)\n",
      "('even', 26081)\n",
      "('bit', 25904)\n",
      "('fits', 25884)\n",
      "('long', 25654)\n",
      "('feet', 25123)\n",
      "('still', 23872)\n",
      "('recommend', 23301)\n",
      "('back', 22956)\n",
      "('big', 22913)\n",
      "('work', 22482)\n",
      "('wearing', 22323)\n",
      "('could', 21558)\n",
      "('pretty', 21510)\n",
      "('looking', 21485)\n",
      "('cute', 21380)\n",
      "('material', 20985)\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "Fdist = FreqDist(StoppedRevisedWords) #Evaluated the frequency distribution of each word in the StoppedRevisedWords corpus\n",
    "Top50 = Fdist.most_common(50) #Stored the top 50 words that have occured most frequently \n",
    "for pair in Top50: #Displayed the top 50 words\n",
    "    print (pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isalpha(w):\n",
    "    if w.isalpha():\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(Words)\n",
    "finder.apply_word_filter(isalpha)\n",
    "finder.apply_word_filter(lambda w: w in Stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('well', 'made'), 0.0004659809938034675)\n",
      "(('would', 'recommend'), 0.0003272013946439088)\n",
      "(('good', 'quality'), 0.0003203846989221607)\n",
      "(('highly', 'recommend'), 0.00028099356410259346)\n",
      "(('really', 'like'), 0.0002634574842687835)\n",
      "(('fit', 'perfectly'), 0.00023234004883668143)\n",
      "(('fit', 'well'), 0.0002272925718518756)\n",
      "(('look', 'like'), 0.0002227654533191116)\n",
      "(('looks', 'great'), 0.00021282660688511245)\n",
      "(('another', 'pair'), 0.00020044207572651667)\n",
      "(('look', 'great'), 0.00019601902888416104)\n",
      "(('looks', 'like'), 0.00018826568794873762)\n",
      "(('feel', 'like'), 0.00018228156575025647)\n",
      "(('year', 'old'), 0.00018176120729821463)\n",
      "(('great', 'price'), 0.0001750485832668749)\n",
      "(('even', 'though'), 0.0001697929629012523)\n",
      "(('fit', 'great'), 0.00016609841789175524)\n",
      "(('usually', 'wear'), 0.00016177944273980797)\n",
      "(('light', 'weight'), 0.00015324556412632181)\n",
      "(('one', 'size'), 0.0001490306606647829)\n",
      "(('normally', 'wear'), 0.00014845826636753688)\n",
      "(('long', 'time'), 0.00014616868917855278)\n",
      "(('would', 'buy'), 0.0001457003665717151)\n",
      "(('fits', 'well'), 0.00014424336290599799)\n",
      "(('every', 'day'), 0.0001399243877540507)\n",
      "(('arch', 'support'), 0.00013883163500476284)\n",
      "(('size', 'larger'), 0.00013534523337608252)\n",
      "(('look', 'good'), 0.00013456469569801975)\n",
      "(('little', 'bit'), 0.00012941314702280554)\n",
      "(('first', 'time'), 0.00012806021504749675)\n",
      "(('half', 'size'), 0.00012639506800096286)\n",
      "(('fits', 'perfectly'), 0.00012623896046535033)\n",
      "(('really', 'nice'), 0.00012587470954892102)\n",
      "(('much', 'better'), 0.0001243136341927955)\n",
      "(('great', 'quality'), 0.00011895394213676456)\n",
      "(('looks', 'good'), 0.00011817340445870181)\n",
      "(('high', 'quality'), 0.00011796526107788507)\n",
      "(('perfect', 'fit'), 0.00011603993480533026)\n",
      "(('different', 'colors'), 0.00011343814254512106)\n",
      "(('long', 'enough'), 0.00011182503134379135)\n",
      "(('fits', 'great'), 0.00011052413521368677)\n",
      "(('would', 'definitely'), 0.00010901509570276543)\n",
      "(('flip', 'flops'), 0.00010823455802470267)\n",
      "(('definitely', 'recommend'), 0.00010110564723172946)\n",
      "(('second', 'pair'), 0.00010084546800570854)\n",
      "(('really', 'cute'), 9.959660772080812e-05)\n",
      "(('super', 'cute'), 9.652649285376127e-05)\n",
      "(('size', 'smaller'), 9.605817024692361e-05)\n",
      "(('make', 'sure'), 9.600613440171942e-05)\n",
      "(('good', 'price'), 9.569391933049433e-05)\n"
     ]
    }
   ],
   "source": [
    "for BigramScore in scored[:50]:\n",
    "    print(BigramScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(Words)\n",
    "finder2.apply_word_filter(isalpha)\n",
    "finder2.apply_word_filter(lambda w: w in Stopwords)\n",
    "finder2.apply_freq_filter(5)\n",
    "scored2 = finder2.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('badgley', 'mischka'), 21.873990889369754)\n",
      "(('salvatore', 'exte'), 21.873990889369754)\n",
      "(('spatestruck', 'lenders'), 21.873990889369754)\n",
      "(('tessuto', 'vela'), 21.873990889369754)\n",
      "(('krav', 'maga'), 21.610956483535958)\n",
      "(('pepto', 'bismol'), 21.610956483535958)\n",
      "(('herman', 'munster'), 21.38856406219951)\n",
      "(('hypo', 'allergenic'), 21.38856406219951)\n",
      "(('birko', 'flor'), 21.195918984257112)\n",
      "(('myia', 'passiello'), 21.195918984257112)\n",
      "(('norman', 'reedus'), 21.195918984257112)\n",
      "(('hola', 'gente'), 21.166171640863062)\n",
      "(('saudi', 'arabia'), 21.166171640863062)\n",
      "(('charlotte', 'russe'), 20.873990889369754)\n",
      "(('giorgio', 'brutini'), 20.87399088936975)\n",
      "(('grady', 'harp'), 20.736487365619816)\n",
      "(('sherpani', 'soleil'), 20.710492157086872)\n",
      "(('laurel', 'burch'), 20.58448427217477)\n",
      "(('fecha', 'indicada'), 20.514094944283368)\n",
      "(('caslynn', 'lizzie'), 20.511420809985044)\n",
      "(('carolyn', 'pollack'), 20.441031482093646)\n",
      "(('vince', 'camuto'), 20.441031482093642)\n",
      "(('buenas', 'tardes'), 20.38856406219951)\n",
      "(('muk', 'luks'), 20.369948384032163)\n",
      "(('liz', 'claiborne'), 20.32144986634097)\n",
      "(('juanita', 'wilson'), 20.289028388648592)\n",
      "(('strawberry', 'shortcake'), 20.195918984257116)\n",
      "(('hanky', 'panky'), 20.195918984257112)\n",
      "(('yak', 'trax'), 20.177997076259853)\n",
      "(('bon', 'bebe'), 20.17355117122866)\n",
      "(('audrey', 'hepburn'), 20.147555962695716)\n",
      "(('muay', 'thai'), 20.0259939828148)\n",
      "(('darth', 'vader'), 20.010052438945777)\n",
      "(('nether', 'regions'), 19.999521771453608)\n",
      "(('hallux', 'limitus'), 19.973526562920668)\n",
      "(('alt', 'alt'), 19.964964549417243)\n",
      "(('gloria', 'vanderbilt'), 19.947991470813527)\n",
      "(('pom', 'poms'), 19.947991470813527)\n",
      "(('aurora', 'borealis'), 19.87399088936975)\n",
      "(('puerto', 'rico'), 19.87399088936975)\n",
      "(('tai', 'chi'), 19.87399088936975)\n",
      "(('ros', 'hommerson'), 19.803601561478356)\n",
      "(('buzz', 'lightyear'), 19.803601561478352)\n",
      "(('viet', 'nam'), 19.791528729177777)\n",
      "(('tuckable', 'lengthprior'), 19.73648736561982)\n",
      "(('prima', 'donna'), 19.688124344058416)\n",
      "(('haute', 'couture'), 19.663423903430093)\n",
      "(('koh', 'koh'), 19.610956483535958)\n",
      "(('onitsuka', 'tigers'), 19.610956483535958)\n",
      "(('libby', 'sue'), 19.558489063641822)\n"
     ]
    }
   ],
   "source": [
    "for PmiScore in scored2[:50]:\n",
    "    print(PmiScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.', 'It', 'doe', \"n't\", 'look', 'cheap', 'at', 'all', '.', 'I', \"'m\", 'so', 'glad', 'I', 'looked', 'on', 'Amazon', 'and', 'found', 'such', 'an', 'affordable', 'tutu', 'that', 'is', \"n't\", 'made', 'poorly', '.', 'A++', 'I', 'bought', 'this', 'for', 'my', '4', 'yr', 'old', 'daughter', 'for', 'dance', 'class', ',', 'she', 'wore', 'it', 'today', 'for', 'the', 'first', 'time', 'and', 'the', 'teacher', 'thought', 'it', 'wa', 'adorable', '.', 'I', 'bought', 'this', 'to', 'go', 'with', 'a', 'light', 'blue', 'long', 'sleeve', 'leotard', 'and', 'wa', 'happy', 'the', 'color', 'matched', 'up', 'great', '.', 'Price', 'wa', 'very', 'good', 'too', 'since', 'some', 'of', 'these', 'go', 'for', 'over', '$', '15.00', 'dollar', '.', 'What', 'can', 'I', 'say', '...', 'my', 'daughter', 'have', 'it', 'in', 'orange', ',', 'black', ',', 'white', 'and', 'pink', 'and', 'I', 'am', 'thinking', 'to', 'buy', 'for', 'they', 'the', 'fuccia', 'one', '.', 'It', 'is', 'a', 'very', 'good', 'way', 'for', 'exalt', 'a', 'dancer', 'outfit', ':', 'great', 'color', ',', 'comfortable', ',', 'look', 'great', ',', 'easy', 'to', 'wear', ',', 'durables', 'and', 'little', 'girl', 'love', 'it', '.', 'I', 'think', 'it', 'is', 'a', 'great', 'buy', 'for', 'costumer', 'and', 'play', 'too', '.', 'We', 'bought', 'several', 'tutu', 'at', 'once', ',', 'and', 'they', 'are', 'got', 'high', 'review', '.', 'Sturdy', 'and', 'seemingly', 'well-made', '.', 'The']\n"
     ]
    }
   ],
   "source": [
    "lemma = nltk.WordNetLemmatizer()\n",
    "reviewLemma = [lemma.lemmatize(t) for t in Tokens]\n",
    "print(reviewLemma[:200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
