{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "from nltk import *\n",
    "\n",
    "from nltk.corpus import sentence_polarity\n",
    "import random\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')\n",
    "Text = mycorpus.raw(\"new_file.txt\")\n",
    "Text = Text.replace(\"reviewText:\",\"\")\n",
    "NewText = nltk.sent_tokenize(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140642"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentence_polarity.sents()\n",
    "documents = [(sent, cat) for cat in sentence_polarity.categories() for sent in sentence_polarity.sents(categories=cat)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = [word for (sent,cat) in documents for word in sent]\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(3000)\n",
    "word_features = [word for (word,count) in word_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(document_features(a, word_features), b) for (a, b) in documents]\n",
    "train_set, test_set = featuresets[1000:], featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent=[]\n",
    "neg_sent=[]\n",
    "for i in NewText:\n",
    "    tokentext = nltk.word_tokenize(i)\n",
    "    Words = [w.lower() for w in tokentext]\n",
    "    RevisedWords = [w for w in Words if w.isalpha()]\n",
    "    StoppedRevisedWords = [w for w in RevisedWords if w not in Stopwords]\n",
    "    category = classifier.classify(document_features(StoppedRevisedWords,word_features))\n",
    "    if (category == \"pos\"):\n",
    "        pos_sent.append(i)\n",
    "    else:\n",
    "        neg_sent.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440573\n",
      "700069\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_sent))\n",
    "print(len(neg_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NOT_features(document, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = False\n",
    "        features['contains(NOT{})'.format(word)] = False\n",
    "    for i in range(0, len(document)):\n",
    "        word = document[i]\n",
    "        if ((i + 1) < len(document)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['contains(NOT{})'.format(document[i])] = (document[i] in word_features)\n",
    "        else:\n",
    "            features['contains({})'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOT_featuresets = [(NOT_features(c, word_features, negationwords), d) for (c, d) in documents]\n",
    "train_set1, test_set1 = NOT_featuresets[1000:], NOT_featuresets[:1000]\n",
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set1)\n",
    "nltk.classify.accuracy(classifier1, test_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent1=[]\n",
    "neg_sent1=[]\n",
    "for i in NewText:\n",
    "    tokentext = nltk.word_tokenize(i)\n",
    "    Words = [w.lower() for w in tokentext]\n",
    "    RevisedWords = [w for w in Words if w.isalpha()]\n",
    "    StoppedRevisedWords = [w for w in RevisedWords if w not in Stopwords]\n",
    "    category = classifier1.classify(NOT_features(StoppedRevisedWords,word_features,negationwords))\n",
    "    if (category == \"pos\"):\n",
    "        pos_sent1.append(i)\n",
    "    else:\n",
    "        neg_sent1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447447\n",
      "693195\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_sent1))\n",
    "print(len(neg_sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier2 = SklearnClassifier(BernoulliNB()).train(train_set)\n",
    "nltk.classify.accuracy(classifier2, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier3 = SklearnClassifier(BernoulliNB()).train(train_set1)\n",
    "nltk.classify.accuracy(classifier3, test_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent2=[]\n",
    "neg_sent2=[]\n",
    "for i in NewText:\n",
    "    tokentext = nltk.word_tokenize(i)\n",
    "    Words = [w.lower() for w in tokentext]\n",
    "    RevisedWords = [w for w in Words if w.isalpha()]\n",
    "    StoppedRevisedWords = [w for w in RevisedWords if w not in Stopwords]\n",
    "    category = classifier3.classify(NOT_features(StoppedRevisedWords,word_features,negationwords))\n",
    "    if (category == \"pos\"):\n",
    "        pos_sent2.append(i)\n",
    "    else:\n",
    "        neg_sent2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431938\n",
      "708704\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_sent2))\n",
    "print(len(neg_sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful vibrant color.',\n",
       " 'I bought several more colors!',\n",
       " 'Nice and puffy tutu skirt.',\n",
       " 'Bought this for my niece as part of her fairy outfit.',\n",
       " 'I bought this for her for Christmas and she never wanted to take it off.']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sent1[30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can't recommend.\",\n",
       " 'Fits great and easy to  clean!',\n",
       " 'Never GOT this item - but gave a 1 STAR because the replies from the SUPPLIER was GREAT.They tried to send the item more than once.My $ was refunded in a timely manner too.It was a shame I never got it for my daughter - it would of looked great with her OUTFIT for Dr. Seuss WEEK at school.Most original.Maybe next time.',\n",
       " 'I would recommend this for girls under 10 yr. old.',\n",
       " 'It will be too short and small for older girls.']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sent1[30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentences=open(\"pos_sentences.txt\",\"w\")\n",
    "for line in pos_sent1:\n",
    "    pos_sentences.write(line)\n",
    "pos_sentences.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sentences=open(\"neg_sentences.txt\",\"w\")\n",
    "for line in neg_sent1:\n",
    "    neg_sentences.write(line)\n",
    "neg_sentences.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
